{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1c911-e8b8-4546-9688-177125801d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ipyannotations.images import PointAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39234f-e478-4c06-872f-79f027b814f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "dataset_path = \"/PATH/TO/DATA\"\n",
    "for category in [c for c in os.listdir(dataset_path) if c != \"empty\"]:\n",
    "    files = [file for file in os.listdir(\n",
    "        os.path.join(dataset_path, category, \"cropped_rgb\")) if \".png\" in file\n",
    "    ]\n",
    "    groups = {}\n",
    "    for file in files:\n",
    "        *prefix, _ = os.path.splitext(file)[0].split(\"_\")\n",
    "        prefix_str = \"_\".join(prefix)\n",
    "        if prefix_str not in groups:\n",
    "            groups[prefix_str] = [file]\n",
    "        else:\n",
    "            groups[prefix_str].append(file)\n",
    "\n",
    "    for prefix, files in sorted(groups.items()):\n",
    "        images.append(os.path.join(dataset_path, category, \"cropped_rgb\", sorted(files)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae733d0-ce6f-451f-9c0a-fd00cdb75e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def visualize_gt(img, sample):\n",
    "    gt_colors = [(255, 0, 0), (0, 255, 0)]\n",
    "    for arm, gt_color in zip(\n",
    "        [\"left\", \"right\"], gt_colors\n",
    "    ):\n",
    "        if f\"{arm}_pick\" in sample:\n",
    "            pick = (\n",
    "                sample[f\"{arm}_pick\"]\n",
    "            )\n",
    "            place = (\n",
    "                sample[f\"{arm}_place\"]\n",
    "            )\n",
    "            img = _pick_place_viz(\n",
    "                img,\n",
    "                pick,\n",
    "                place,\n",
    "                color=gt_color,\n",
    "            )\n",
    "    return img\n",
    "\n",
    "def _pick_place_viz(img, picks, places, color):\n",
    "    if not isinstance(picks, list) and len(picks.shape) == 1:\n",
    "        picks = [picks]\n",
    "        places = [places]\n",
    "    for pick, place in zip(picks, places):\n",
    "        if pick[0] >= 0:\n",
    "            cv2.circle(\n",
    "                img=img,\n",
    "                center=(round(pick[0]), round(pick[1])),\n",
    "                radius=3,\n",
    "                color=color,\n",
    "                thickness=2,\n",
    "            )\n",
    "        if place[0] >= 0:\n",
    "            cv2.arrowedLine(\n",
    "                img=img,\n",
    "                pt1=(round(pick[0]), round(pick[1])),\n",
    "                pt2=(round(place[0]), round(place[1])),\n",
    "                color=color,\n",
    "                thickness=2,\n",
    "            )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c7035-9f45-458c-adfa-4be2b2f62ac7",
   "metadata": {},
   "source": [
    "# Annotation instructions\n",
    "\n",
    "Bear in mind that the origin of the manipulation for both arms has to be in the cloth region.\n",
    "The next image is the state to which you try to reach doing your manipulation. If the next image is unrelated there is no need to label anything.\n",
    "\n",
    "The instructions are:\n",
    "1. With \"left-arm\" class selected (done by default), click first the \"from\" point and then the \"to\" point for the left arm.\n",
    "2. Select \"right-arm\" class\n",
    "3. Click first the \"from\" point and then the \"to\" point for the right arm.\n",
    "4. If you want to annotate another bimanual manipulation, select \"left-arm\" class and go to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1cff84-7d7d-41eb-b7bc-7ee9c3f3e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1 #Add index of image to annotate\n",
    "\n",
    "image = images[idx]\n",
    "\n",
    "widget = PointAnnotator(options=[\"left-arm\", \"right-arm\"])\n",
    "widget.display(image)\n",
    "widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795cf51-ce9f-466d-832b-f79b5399dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if widget.data:\n",
    "    assert len(widget.data) % 4 == 0, f\"Error for widget {i} with length {len(widget.data)}\"\n",
    "    num_chunks = len(widget.data) // 4\n",
    "    \n",
    "    coords = []\n",
    "    for chunk_idx in range(num_chunks):\n",
    "        chunk = widget.data[chunk_idx * 4:(chunk_idx + 1) * 4]\n",
    "        assert \"left\" in chunk[0][\"label\"] and \"left\" in chunk[1][\"label\"] and \"right\" in chunk[2][\"label\"] and \"right\" in chunk[3][\"label\"], f\"Failed for widget{i}\"\n",
    "        from_left = chunk[0][\"coordinates\"]\n",
    "        from_right = chunk[2][\"coordinates\"]\n",
    "\n",
    "        *path, _, filename = image.split(os.path.sep)\n",
    "        annotations_dir = os.path.join(*path, \"cropped_annotations\")\n",
    "        os.makedirs(annotations_dir, exist_ok=True)\n",
    "\n",
    "        mask = (np.asarray(Image.open(os.path.join(*path, \"cropped_mask\", filename)))[:, :, 0] / 255).astype(bool)\n",
    "        if mask[from_left[1], from_left[0]] and mask[from_right[1], from_right[0]]:\n",
    "            *prefix, _ = os.path.splitext(filename)[0].split(\"_\")\n",
    "            annotations_file = os.path.join(annotations_dir, \"_\".join(prefix) + \".npy\")\n",
    "            \n",
    "            coords.append(np.array([*[point[\"coordinates\"] for point in chunk]]).flatten())\n",
    "    if coords:\n",
    "        coords = np.array(coords)\n",
    "        if os.path.isfile(annotations_file):\n",
    "            print(f\"Updating {annotations_file}\")\n",
    "            saved_coords = np.load(annotations_file)\n",
    "            if len(saved_coords.shape) == 1:\n",
    "                saved_coords = saved_coords[None, :]\n",
    "            np.save(annotations_file, np.unique(np.r_[saved_coords, coords]))\n",
    "        else:\n",
    "            print(f\"Creating {annotations_file}\")\n",
    "            np.save(annotations_file, coords)\n",
    "    else:\n",
    "        print(f\"Erronous data\")\n",
    "else:\n",
    "    print(f\"\\tWidget has no data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2fe0a-9ffe-4440-b753-2691a4c6ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in [c for c in os.listdir(dataset_path) if c != \"empty\"]:\n",
    "    if os.path.isdir(os.path.join(dataset_path, category, \"cropped_annotations\")):\n",
    "        for file in os.listdir(\n",
    "            os.path.join(dataset_path, category, \"cropped_annotations\")\n",
    "        ):\n",
    "            if os.path.isfile(os.path.join(dataset_path, category, \"cropped_annotations\", file)):\n",
    "                annotation = np.load(os.path.join(dataset_path, category, \"cropped_annotations\", file))\n",
    "                if len(annotation.shape) == 1:\n",
    "                    annotation = annotation[None, :]\n",
    "        \n",
    "                img = np.asarray(Image.open(os.path.join(dataset_path, category, \"cropped_rgb\", file.replace(\".npy\", \"_0000.png\"))))\n",
    "                \n",
    "                visualization = visualize_gt(img, {\n",
    "                    \"left_pick\": annotation[:, [0, 1]],\n",
    "                    \"left_place\": annotation[:, [2, 3]],\n",
    "                    \"right_pick\": annotation[:, [4, 5]],\n",
    "                    \"right_place\": annotation[:, [6, 7]],\n",
    "                })\n",
    "        \n",
    "                os.makedirs(os.path.join(dataset_path, category, \"cropped_viz\"), exist_ok=True)\n",
    "                Image.fromarray(visualization).save(os.path.join(dataset_path, category, \"cropped_viz\", file.replace(\".npy\", \".png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36271b1b-cfec-40ee-b0b0-2d5b232a9717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
